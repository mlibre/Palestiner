task: llm
base_model: microsoft/Phi-3.5-mini-instruct
project_name: palestineInformationAI
log: tensorboard
backend: local

data:
  path: /content/dataset/
  train_split: train
  valid_split: null
  chat_template: null
  column_mapping:
    text_column: text

params:
  trainer: sft
  # max_seq_length (int) — Maximum sequence length for the input. Default is 128. https://stackoverflow.com/questions/76547541/huggingface-how-do-i-find-the-max-length-of-a-model
  # model_max_length (int) — Maximum length of the model input. Default is 2048.
  epochs: 5
  batch_size: 2
  lr: 1e-5
  peft: true
  quantization: int4
  target_modules: all-linear
  padding: right
  optimizer: paged_adamw_8bit
  scheduler: cosine
  gradient_accumulation: 8
  mixed_precision: bf16
  merge_adapter: true

hub:
  username: ${HF_USERNAME}
  token: ${HF_TOKEN}
  push_to_hub: false
